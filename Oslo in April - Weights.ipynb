{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=\"oslo_fram_round.png\" height=50 width=50 align=\"left\"></div><div style=\"margin-left:70px\"><h1>$\\mathrm{Oslo}_{\\mathrm{MS}}$ - April</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathrm{Oslo}_{\\mathrm{MS}}$ is an **O**pportunity for (Semi)-**S**upervised **L**earning **O**f **M**athematics and **S**tatistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format\n",
    "\n",
    "* Every month a mathematical/statistical theme is proposed by the *supervisor*.\n",
    "* A set of lines of investigation around the theme is proposed, along with reading material.\n",
    "* For every line of investigation, at least 1 programming exercise is proposed.\n",
    "* Free exploration and additional self-thought lines/exercises are encouraged.\n",
    "* Starting from a duplication of Jupyter notebook, material is worked through and enriched by *learner*.\n",
    "* After the *learner* is satisfied with the results of his $\\mathrm{Oslo}_{\\mathrm{MS}}$ activities, a review session with *supervisor* is scheduled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General references\n",
    "\n",
    "* [LAS] Linear Algebra by G Strang (in folder `P:\\Development\\oslo\\references`)\n",
    "* [MML] [Mathematics for Machine Learning](https://mml-book.github.io/) (pdf [here](https://mml-book.github.io/book/mml-book.pdf))\n",
    "* [PRML] [Pattern Recognition and Machine Learning by C Bishop](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# April Theme - Weight\n",
    "\n",
    "* it is a positive (or zero) scalar value (i.e. a single real number).\n",
    "  The word *scalar* is used is to emphasize that it will be used to multiply a *vector* (to produce a new vector).\n",
    "  \n",
    "(*what is a vector, by the way?*)\n",
    "\n",
    "*Answer*: A vector is an array of numbers, each number represents how far it stretches the space on the direction of the baisis vectors. A vector can represent direction and speed, position in a space, a combination of features and more. \n",
    "\n",
    "#### question\n",
    "\n",
    "Examples of weights that you know of?\n",
    "\n",
    "*Answer*: weighted average, weightd sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalizing weights\n",
    "\n",
    "* often a series of weights $w_i$ (with $i=1 \\ldots n$) is *normalized*, that is, for all $i$, $0 \\leq w_i \\leq 1$ and\n",
    "  $\\sum w_i = 1$.\n",
    "* if a series of weights $w_i'$ is not normalized, how can you obtain a series of normalized weights proportional to the original series of weight?\n",
    "\n",
    "### exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement a function that passes tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(weights: List[float]) -> List[float]:\n",
    "    # fix the implementation\n",
    "    w = np.array(weights)\n",
    "    if w.min() < 0:\n",
    "        w = w - w.min() + 1\n",
    "    return w / w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.2,  0.3,  0.4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize([1.0,2.0,3.0,4.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(weights: List[float], normalized: List[float]) -> bool:\n",
    "    if len(weights) != len(normalized):\n",
    "        return False\n",
    "    if not math.isclose(sum(normalized), 1):\n",
    "        return False\n",
    "    for w in normalized:\n",
    "        if w < 0 or w > 1:\n",
    "            return False\n",
    "    c = None\n",
    "    for i in range(len(weights)):\n",
    "        if weights[i] != 0 and c is None:\n",
    "            c = normalized[i] / weights[i]\n",
    "        if c is not None and not math.isclose(c*weights[i], normalized[i]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = [\n",
    "    # add your own!\n",
    "    [0.5, 0.5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [0.5, 0.3, 0.3],\n",
    "    [random.uniform(0, 1000) for _ in range(1000)],\n",
    "    [1, 1000, 1000_000, 1000_000_000],\n",
    "    [0.6, 100.0, 12, -2.0, 3456.0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ok\n",
      "1: ok\n",
      "2: ok\n",
      "3: ok\n",
      "4: ok\n",
      "5: ok\n",
      "6: "
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-cc632c3fd515>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\": \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, test in enumerate(test_vectors):\n",
    "    print(i, end=\": \")\n",
    "    assert check(test, normalize(test))\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimal weight for a mixture of two vectors\n",
    "\n",
    "For two vectors $v$ and $w$ a mixture of $v$ and $w$ is a weighted averaged $\\alpha \\cdot v + (1- \\alpha) w$\n",
    "with $0 \\leq \\alpha \\leq 1$.\n",
    "\n",
    "### exercise\n",
    "\n",
    "Suppose $f_1$ and $f_2$ are two competing time series forecast over a period (represented as vectors), where the demand is given by $d$. \n",
    "\n",
    "Can you find an optimal mixture (the optimal weight $\\alpha$) of $f_1$ and $f_2$ that minimizes root mean squared error?\n",
    "\n",
    "Implement a function that does it and test it in a few cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exponential smoothing\n",
    "\n",
    "* exponential smoothing is a simple but effective tecnique to smooth time series.\n",
    "* exponential smoothing is a **weighted** average of past observations and is usually a better alternative to a moving average.\n",
    "* exponential smoothing depends on a coefficient $\\alpha$\n",
    "\n",
    "### exercise\n",
    "\n",
    "* look up definition of exponential smoothing\n",
    "* implement exponential smoothing and moving average for a time series and compare the two on one or more examples (with a plot)\n",
    "* bonus: look up and implement double exponential smoothing (which is a very basic version of forecasting in SO99+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribute balls into boxes according to weights\n",
    "\n",
    "* Look up the implementation of `tgmle.utils.clust_utils.balls_in_boxes`.\n",
    "\n",
    "\n",
    "### exercise\n",
    "\n",
    "* Can you find test vectors for that function that would give full test coverage?\n",
    "* The function is recursive (through function `update_call`). Can you find an example where the recursion is called at least 3 times? 10 times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weights and linear algebra\n",
    "\n",
    "* statement: a set of vectors a linearly dependent if there is a set of weights not all zero for which the vector obtained by linear combination of vectors and weight is the zero vector\n",
    "\n",
    "### exercise\n",
    "\n",
    "* look up chapter 2.3 in [LAS] reference above and pick up some exercise to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## probabilities as weights\n",
    "\n",
    "* a probability $p$ is a value between $0$ and $1$. Probabilities can be thought as weights!\n",
    "\n",
    "### exercise\n",
    "\n",
    "* what is the expectation of a random variable in terms of weights?\n",
    "* simulate a random walk in the plane where starting from $(0, 0)$ every successive step is taken according to one of two probabilistic rules:\n",
    "\n",
    "    A. (pawn) step is drawn between $(0, 1), (1, 1), (-1, 1)$. Suppose that i) probabilty to go forward is 4 times the probability to go in a diagonal direction and that ii) probability for the pawn to go towards right is 2 times the probabilty to go towards left.\n",
    "    \n",
    "    B. (backward horse) step is drawn between $(-1, -2), (-2, -1), (2, -1), (1, -2)$. Suppose that probabilty to take a shorter step backward is 3 times the probabilty of taking a longer step backward and that the probabilty of going towards left is 9 times higher than the probability of going right.\n",
    "\n",
    "\n",
    "* derivate the probabilities for each vector of rule A starting from \"non normalized\" probabilities and using normalize function you implemented (e.g. let's assign 1 to \"probability\" of vector $(1, 1)$ and draw consequences for other probabilties).\n",
    "* do the same for rule B (are the constraint enough to compute the probabilities? if not add a constraint).\n",
    "* simulate the random walk for 1000 steps assuming that at every step we pick between rule A and rule B according to a flip of a fair coin. Make a plot. What is the expected position?\n",
    "* what would be the optimal mixture of rules in order to have the expected position to be always the origin (independently of the number of steps?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
